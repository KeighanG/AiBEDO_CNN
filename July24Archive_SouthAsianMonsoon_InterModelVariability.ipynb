{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63e50453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "t\n",
    "import geocat.comp\n",
    "from datetime import datetime\n",
    "import dask\n",
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import netCDF4\n",
    "import os\n",
    "import proplot as pplt\n",
    "import warnings\n",
    "from numpy import meshgrid, deg2rad, gradient, cos, sin\n",
    "from xarray import DataArray\n",
    "from scipy import stats\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.preprocessing import StandardScaler as scale\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b542ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318376b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec7f663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090b2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d719866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6626e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to AWS S3 storage\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "## By downloading the master CSV file enumerating all available data stores, we can interact with the spreadsheet\n",
    "## through a pandas DataFrame to search and explore for relevant data using the CMIP6 controlled vocabulary:\n",
    "\n",
    "df = pd.read_csv(\"https://cmip6-pds.s3.amazonaws.com/pangeo-cmip6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfc2112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(qstring):\n",
    "    df_subset = df.query(qstring)\n",
    "    if df_subset.empty:\n",
    "        print('data not available for '+qstring)\n",
    "    else:\n",
    "        for v in df_subset.zstore.values:\n",
    "            zstore = v\n",
    "            mapper = fs.get_mapper(zstore)\n",
    "            return_ds = xr.open_zarr(mapper, consolidated=True)\n",
    "    return(return_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf3eb84b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'sel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m cres\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m=\u001b[39mt1\u001b[38;5;241m.\u001b[39munstack()\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m#Select only the SAM lat,lon range: 60-100E, 10-30N \u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m regridland\u001b[38;5;241m=\u001b[39m\u001b[43mregridland\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msel\u001b[49m(lon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m100\u001b[39m),lat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m30\u001b[39m))\n\u001b[1;32m     56\u001b[0m precip\u001b[38;5;241m=\u001b[39mprec\u001b[38;5;241m.\u001b[39msel(lon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m100\u001b[39m),lat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m30\u001b[39m))\n\u001b[1;32m     57\u001b[0m precip\u001b[38;5;241m=\u001b[39mxr\u001b[38;5;241m.\u001b[39mwhere(regridland\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m,np\u001b[38;5;241m.\u001b[39mnan,precip) \u001b[38;5;66;03m#remove oceans, monsoon is defined as only over land \u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'sel'"
     ]
    }
   ],
   "source": [
    "#Load in model data\n",
    "modelNames=['CESM2','CESM2-FV2','CESM2-WACCM','CESM2-WACCM-FV2','CMCC-CM2-SR5','CanESM5',\n",
    "'E3SM-1-1','E3SM-1-1-ECA','GFDL-CM4','GFDL-ESM4','GISS-E2-1-H','MIROC-ES2L','MIROC6'\n",
    ",'MPI-ESM-1-2-HAM','MPI-ESM1-2-HR','MRI-ESM2-0']\n",
    "\n",
    "membList=[\"'r1i1p1f1'\"]\n",
    "\n",
    "precmeanlist=[]\n",
    "cresmeanlist=[]\n",
    "\n",
    "for m,i in zip(modelNames,membList):\n",
    "    inputStr  = \"activity_id=='CMIP' & table_id=='Amon' & experiment_id=='historical' &  member_id=='r1i1p1f1' & variable_id==\"\n",
    "    altinputStr  = \"activity_id=='CMIP' & table_id=='fx' & experiment_id=='historical' &  member_id=='r1i1p1f1' & variable_id==\"\n",
    "    rsut_ds   = getData(inputStr+\"'rsut'\")\n",
    "    pr_ds     = getData(inputStr+\"'pr'\")\n",
    "    rsutcs_ds = getData(inputStr+\"'rsutcs'\")\n",
    "    sftlf_ds = getData(altinputStr+\"'sftlf'\")\n",
    "   \n",
    "    cres= rsutcs_ds.rsutcs-rsut_ds.rsut\n",
    "    prec=pr_ds.pr\n",
    "    land=sftlf_ds.sftlf\n",
    "    \n",
    "    lats=prec.lat\n",
    "    lons=prec.lon\n",
    "    landlat=land.lat\n",
    "    landlon=land.lon\n",
    "    \n",
    "    land=land.to_numpy()\n",
    "    #Regrid land to a common grid\n",
    "    X, Y =np.meshgrid(landlon,landlat)\n",
    "    lat1=lats\n",
    "    lon1=lons\n",
    "    XI,YI=np.meshgrid(lon1,lat1)\n",
    "    \n",
    "    regridland=griddata((X.flatten(),Y.flatten()), land.flatten(), (XI,YI), method='nearest')\n",
    "    regridland=xr.DataArray(regridland,coords=[lat1,lon1],dims=['lat','lon'])\n",
    "    regridland=np.expand_dims(regridland,axis=0)\n",
    "    \n",
    "    #Select July Month Indexes\n",
    "    month_idxs=cres.groupby('time.month').groups\n",
    "    july_idxs=month_idxs[7]\n",
    "    cres=cres.isel(time=july_idxs)\n",
    "    prec=prec.isel(time=july_idxs)\n",
    "    time=cres.time\n",
    "    \n",
    "    t1=cres.stack(z=(\"lat\", \"lon\"))\n",
    "    # fit scaler on training data\n",
    "    norm = scale().fit(t1)\n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    cres.values=t1.unstack()\n",
    "    \n",
    "    \n",
    "    #Select only the SAM lat,lon range: 60-100E, 10-30N \n",
    "    regridland=regridland.sel(lon=slice(60,100),lat=slice(10,30))\n",
    "    precip=prec.sel(lon=slice(60,100),lat=slice(10,30))\n",
    "    precip=xr.where(regridland==0,np.nan,precip) #remove oceans, monsoon is defined as only over land \n",
    "\n",
    "    #Do weighted correction on precipitation\n",
    "    weights=np.cos(np.deg2rad(precip.lat))\n",
    "    prec_index=precip.weighted(weights).mean(dim=('lat','lon'))\n",
    "    prec_index=prec_index*60*60*24 #conversion to mm/day, exluding dividing by rho and multiplying by 1000mm/m\n",
    "\n",
    "    prec_index=prec_index.to_numpy()\n",
    "    t3=prec_index\n",
    "    t3=t3.reshape(-1,1)\n",
    "    sc_t=scale()\n",
    "    t3=sc_t.fit_transform(t3)\n",
    "    prec_index=t3.mean(axis=1)\n",
    "    print(prec_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb069e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detrend(x:np.ndarray,time:np.ndarray):\n",
    "        nt,nx,ny = x.shape\n",
    "        xtemp = x.reshape(nt,nx*ny)\n",
    "        p = np.polyfit(time, xtemp, deg=3)\n",
    "        #fit=p[0]*(time[:,np.newaxis])+ p[1]\n",
    "        fit = p[0]*(time[:,np.newaxis] **3)+ p[1]*(time[:,np.newaxis]**2) + p[2]*(time[:,np.newaxis]) + p[3]\n",
    "        return x - fit.reshape(nt,nx,ny)\n",
    "\n",
    "def remove_time_mean(x):\n",
    "        return x - x.mean(dim='time')\n",
    "\n",
    "def removeSC(x):\n",
    "        return x.groupby('time.month').apply(remove_time_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb33724",
   "metadata": {},
   "outputs": [],
   "source": [
    "cres_RMSC=removeSC(cres)\n",
    "\n",
    "#Detrend data sets\n",
    "time=cres_RMSC.time\n",
    "cres_july=cres_RMSC.to_numpy()\n",
    "\n",
    "\n",
    "time=time.to_numpy()\n",
    "\n",
    "time=time.astype(int)/10**9\n",
    "\n",
    "cres_july=detrend(cres_july,time)\n",
    "cres_july=xr.DataArray(cres_july,coords=[time,lat,lon],dims=['time','lat','lon'])\n",
    "\n",
    "#test=xr.where(cres_july<0,10,cres_july)\n",
    "#test1=xr.where(test==0,10,test)\n",
    "#print(test1.min())\n",
    "\n",
    "cres_july=xr.where(np.logical_and(cres_july>-1e-14, cres_july<1e-14),0,cres_july)\n",
    "\n",
    "#qq=xr.where(cres_july<=0,10,cres_july)\n",
    "#print(qq.min())\n",
    "\n",
    "\n",
    "#cres_july=cres_july.shift(time=3)\n",
    "\n",
    "test1=cres_july[8,:,:]\n",
    "test=np.mean(cres_july,axis=0)\n",
    "test1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99883c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75b3df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92072a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd8d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c5301e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9becffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d52984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify model names\n",
    "modelNames=['CESM2','CESM2-FV2','CESM2-WACCM','CESM2-WACCM-FV2','CMCC-CM2-SR5',\n",
    "'E3SM-1-1','E3SM-1-1-ECA','FGOALS-g3','GFDL-CM4','GFDL-ESM4','GISS-E2-1-G-CC','SAM0-UNICON'] \n",
    "\n",
    "#Specify model names\n",
    "#modelNames=['CESM2','CESM2-FV2','CESM2-WACCM','CESM2-WACCM-FV2','CMCC-CM2-SR5','E3SM-1-0',\n",
    "#'E3SM-1-1','E3SM-1-1-ECA','EC-Earth3','FGOALS-f3-L','FGOALS-g3','FIO-ESM-2-0','GFDL-CM4','GFDL-ESM4',\n",
    "#'GISS-E2-1-G-CC','IITM-ESM','INM-CM4-8','INM-CM5-0','IPSL-CM6A-LR','KIOST-ESM','MIROC6','MPI-ESM-1-2-HAM',\n",
    "#'MPI-ESM1-2-LR','MRI-ESM2-0','NESM3','NorESM2-LM','NorESM2-MM','SAM0-UNICON','TaiESM1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94fad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cresmeanfinal=cresmeanfinal[5,:,:]\n",
    "cresmeanfinal.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e67f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files='/home/jupyter-dipti/work/ISMR_CITCZ/Data/CESM2_r1i1p1f1_historical.nc'\n",
    "data=xr.open_dataset(files)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ac09a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "download_path='/home/jupyter-dipti/work/ISMR_CITCZ/Data/'\n",
    "inputstr='_r1i1p1f1_historical.nc'\n",
    "\n",
    "precmeanlist=[]\n",
    "cresmeanlist=[]\n",
    "\n",
    "fig,axes=pplt.subplots([[1]],proj='eqearth')\n",
    "#fig.save('SAMonsoon_Intermodel_Variability')\n",
    "for i,name in enumerate(modelNames):\n",
    "    #get input variables in xarray\n",
    "    files=download_path+name+inputstr\n",
    "    data=xr.open_dataset(files)        \n",
    "    lons=data['lon']\n",
    "    lats=data['lat']\n",
    "    \n",
    "    #Regrid land to a common grid\n",
    "    X, Y =np.meshgrid(landlon,landlat)\n",
    "    lat1=lats\n",
    "    lon1=lons\n",
    "    XI,YI=np.meshgrid(lon1,lat1)\n",
    "    \n",
    "    regridland=griddata((X.flatten(),Y.flatten()), land.flatten(), (XI,YI), method='nearest')\n",
    "    regridland=xr.DataArray(regridland,coords=[lat1,lon1],dims=['lat','lon'])\n",
    "    regridland=np.expand_dims(regridland,axis=0)\n",
    "    \n",
    "    cres=(data.rsdt-data.rsut)-(data.rsdt-data.rsutcs)\n",
    "    \n",
    "    #Done getting input variables, now get output variables - precipition\n",
    "    prec=data.pr\n",
    "    prec=prec*60*60*24\n",
    "    prec=np.multiply(regridland,prec)\n",
    "    precip=xr.where(prec==0,np.nan,prec) #remove oceans, monsoon is defined as only over land \n",
    "    \n",
    "    datetimeindex=cres.indexes['time'].to_datetimeindex()\n",
    "    cres['time']=datetimeindex\n",
    "    precip['time']=datetimeindex\n",
    "\n",
    "    \n",
    "    #Select July index\n",
    "    month_idxs=cres.groupby('time.month').groups\n",
    "    july_idxs=month_idxs[7]\n",
    "    test_idxs=month_idxs[7]\n",
    "    cres_july=cres.isel(time=july_idxs)\n",
    "    prec_july=precip.isel(time=july_idxs)\n",
    "    \n",
    "    #cres=cres_july.shift(time=3)\n",
    "\n",
    "    prec_july=xr.where(prec_july<0,0,prec_july) #apply Non-negative precipitation physical constraint\n",
    "\n",
    "    t1=cres.stack(z=(\"lat\", \"lon\"))\n",
    "    # fit scaler on training data\n",
    "    norm = scale().fit(t1)\n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    cres.values=t1.unstack()\n",
    "    #cres=cres.shift(time=3)\n",
    "    \n",
    "    #Select only the SAM lat,lon range: 60-100E, 10-30N \n",
    "    prec_july=prec_july.sel(lon=slice(60,100))\n",
    "    prec_july=prec_july.sel(lat=slice(10,30))\n",
    "\n",
    "    #Do weighted correction on precipitation\n",
    "    weights=np.cos(np.deg2rad(prec.lat))\n",
    "    prec_index=prec_july.weighted(weights).mean(dim=('lat','lon')) \n",
    "    \n",
    "    #Calculate mean of precipitation index, gives a single value for each model\n",
    "    mymean=prec_index.mean()\n",
    "    \n",
    "    precmeanlist.append(mymean) #append list of precipitation standard deviations for each model\n",
    "    #Calculate model CRE , gives a mean for each grid cell \n",
    "    cresmean=cres.mean(axis=0)\n",
    "    \n",
    "    cresmean=cresmean.to_numpy()\n",
    "\n",
    "    #Regrid all models to a common grid\n",
    "    X, Y =np.meshgrid(lons,lats)\n",
    "    lat1=np.linspace(90,-90,360)\n",
    "    lon1=np.linspace(0,360,720)\n",
    "    XI,YI=np.meshgrid(lon1,lat1)\n",
    "    \n",
    "    regridcresmean=griddata((X.flatten(),Y.flatten()), cresmean.flatten(), (XI,YI), method='nearest')\n",
    "    cresmeanlist.append(regridcresmean) #append list of cres standard deviations for each model\n",
    "    \n",
    "    cresmeanstack=np.stack(cresmeanlist,axis=0) #stack the lists to obtain the correct dimensions\n",
    "\n",
    "\n",
    "prmean=xr.DataArray(data=precmeanlist,coords={'models':np.arange(1,len(modelNames)+1)}) \n",
    "\n",
    "\n",
    "condition=np.mean(prmean)+2*np.std(prmean) #calculate the condition to be used in regression calculation\n",
    "\n",
    "cresmeanfinal=xr.DataArray(data=cresmeanstack,coords={'models':np.arange(1,len(modelNames)+1),'lat':lat1,'lon':lon1})\n",
    "\n",
    "prfinal,cresmeanfinal = xr.broadcast(prmean,cresmeanfinal) #broadcast prmean array to fill array to allow regression to be executed\n",
    "\n",
    "\n",
    "#define the regression function\n",
    "def linear_trend(x,y): \n",
    "    mask=np.isfinite(x)&np.isfinite(y)\n",
    "    if len(x[mask])==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        pf=np.polyfit(x[mask],y[mask],1)\n",
    "        return xr.DataArray(pf[0])\n",
    "\n",
    "def ints(x,y):\n",
    "    mask=np.isfinite(x)&np.isfinite(y)\n",
    "    if len(x[mask])==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        ipf=np.polyfit(x[mask],y[mask],1)\n",
    "        return xr.DataArray(ipf[1])\n",
    "\n",
    "#Apply regression function using ufunc to get regression coefficients/slopes\n",
    "slopes=xr.apply_ufunc(linear_trend,\n",
    "                    prfinal,cresmeanfinal,\n",
    "                    vectorize=True,\n",
    "                    dask='parallelized',\n",
    "                    input_core_dims=[['models'],['models']],\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "intercepts=xr.apply_ufunc(ints,\n",
    "                    prfinal,cresmeanfinal,\n",
    "                    vectorize=True,\n",
    "                    dask='parallelized',\n",
    "                    input_core_dims=[['models'],['models']],\n",
    "                    )\n",
    "\n",
    "cresregression=slopes*condition+intercepts\n",
    "con=axes.contourf(lon1,lat1,cresregression,extend='both',colorbar_kw={'label': 'Wm-2'})\n",
    "axes.set_title('CRES Regression')\n",
    "\n",
    "fig.format(coast=True)\n",
    "axes.format(suptitle='South Asian Monsoon July Precipitation CRES Intermodel Variability Regression')\n",
    "cbar=plt.colorbar(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413cb32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8e3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31622da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the data\n",
    "varList=['cres','cresSurf','acres','crel','crelSurf','acrel']\n",
    "regressions=np.stack((cresregression,cresSurfregression,acresregression,crelregression,crelSurfregression,acrelregression))\n",
    "fig,axes=pplt.subplots([[1,2,3],[4,5,6]],proj='eqearth')\n",
    "for j,vname in enumerate(varList):\n",
    "    con=axes[j].contourf(lon1,lat1,regressions[j],extend='both',colorbar_kw={'label': 'Wm-2'})\n",
    "    axes[j].set_title(vname)\n",
    "    \n",
    "fig.format(coast=True)\n",
    "axes.format(suptitle='South Asian Monsoon July Precipitation CRE Intermodel Variability Regression')\n",
    "cbar=plt.colorbar(con)\n",
    "#fig.save('SAMonsoon_Intermodel_Variability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9649b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e380e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages_environment",
   "language": "python",
   "name": "packages"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
