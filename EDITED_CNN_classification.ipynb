{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43f167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from math import e\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv3D, Flatten,MaxPooling3D,AveragePooling3D, concatenate,Input ,SpatialDropout3D,Dropout\n",
    "from sklearn import metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7bfc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing functions\n",
    "\n",
    "#3D detrend function\n",
    "def detrend(x:np.ndarray,time:np.ndarray):\n",
    "        nt,nx,ny = x.shape\n",
    "        xtemp = x.reshape(nt,nx*ny)\n",
    "        p = np.polyfit(time, xtemp, deg=3)\n",
    "        fit = p[0]*(time[:,np.newaxis] **3)+ p[1]*(time[:,np.newaxis]**2) + p[2]*(time[:,np.newaxis]) + p[3]\n",
    "        return x - fit.reshape(nt,nx,ny)\n",
    "    \n",
    "#1D detrend function\n",
    "def altdetrend(x:np.ndarray,time:np.ndarray):\n",
    "        nt = x.shape\n",
    "        xtemp = x.reshape(nt)\n",
    "        p = np.polyfit(time, x, deg=1)\n",
    "        fit = p[0]*(time[:,np.newaxis])+ p[1]\n",
    "        return x - fit.reshape(nt)\n",
    "    \n",
    "def remove_time_mean(x):\n",
    "        return x - x.mean(dim='time')\n",
    "\n",
    "def removeSC(x):\n",
    "        return x.groupby('time.month').apply(remove_time_mean)\n",
    "    \n",
    "# Calculate std normal anomaly\n",
    "def calStdNorAnom(x):\n",
    "    a=[]\n",
    "    for m in np.unique(x.time.dt.month):\n",
    "        mData=x[x.time.dt.month==m]\n",
    "        mRolling=mData.rolling(time=31, center=True).mean().bfill(dim=\"time\").ffill(dim=\"time\")\n",
    "        sRolling=mData.rolling(time=31, center=True).std().bfill(dim=\"time\").ffill(dim=\"time\")\n",
    "        normData=(mData-mRolling)/sRolling\n",
    "        a.append(normData)\n",
    "    combineArray=xr.concat(a,'time')\n",
    "    outArray=combineArray.sortby('time')\n",
    "    return outArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b79472",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d408b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open ERA5 Datasets\n",
    "data=xr.open_dataset('ERA5_Input_Exp8.nc')\n",
    "#Load in preprocessed data\n",
    "cres=data.cres_pre\n",
    "netTOAcs=data.netTOAcs_pre\n",
    "crel=data.crel_pre\n",
    "\n",
    "data1=xr.open_dataset('ERA5_Output_PrecipCon.nc')\n",
    "pr=data1.pr\n",
    "\n",
    "lat=cres.lat\n",
    "lon=cres.lon\n",
    "\n",
    "time=cres.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7d4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Monsoon Months\n",
    "months=[6,7,8,9]\n",
    "leadmonths=[2,3,4,5]\n",
    "#varOut.where(varOut.time.dt.month.isin(months), drop=True) #Change varOut to desired variable\n",
    "prec=pr.where(pr.time.dt.month.isin(months), drop=True)\n",
    "cresIn=cres.where(cres.time.dt.month.isin(leadmonths), drop=True)\n",
    "netTOAcsIn=netTOAcs.where(netTOAcs.time.dt.month.isin(leadmonths), drop=True)\n",
    "crelIn=crel.where(crel.time.dt.month.isin(leadmonths), drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9a2170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "land=data.lsMask\n",
    "land=land.where(land.time.dt.month.isin(months), drop=True)\n",
    "\n",
    "land=land.sel(lon=slice(60,100))\n",
    "land=land[:,240:321,:] #for some reason slicing latitude is producing Nans so I select lat manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "649ce4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only the SAM lat,lon range: 60-100E, 10-30N\n",
    "precip=prec.sel(lon=slice(60,100))\n",
    "precip=precip[:,240:321,:] #Same manual lat selection\n",
    "precip=xr.where(land==0,np.nan,precip) #remove oceans, monsoon is defined as only over land \n",
    "\n",
    "#Do weighted correction on precipitation\n",
    "weights=np.cos(np.deg2rad(precip.lat))\n",
    "prec_index=precip.weighted(weights).mean(dim=('lat','lon'))\n",
    "prec_index=prec_index*60*60*24 #conversion to mm/day, exluding dividing by rho and multiplying by 1000mm/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "764af8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove seasonal cycle\n",
    "prec_index=removeSC(prec_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97a68385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize\n",
    "prec_index=calStdNorAnom(prec_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4190c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detrend\n",
    "time=prec_index.time\n",
    "prec_index=prec_index.to_numpy()\n",
    "time=time.to_numpy()\n",
    "time=time.astype(int)/10**9\n",
    "\n",
    "prec_index=altdetrend(prec_index,time)\n",
    "prec_index=xr.DataArray(prec_index,coords=[time],dims=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77cd5c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create classes based on precipitation index\n",
    "mysd=prec_index.std()\n",
    "mymean=prec_index.mean()\n",
    "\n",
    "test=pd.cut(prec_index, [mymean - mysd* 10000, mymean - mysd * 2,  mymean - mysd, mymean - 0.5*mysd, mymean + 0.5*mysd, mymean + mysd, mymean + mysd *2, mymean + mysd* 10000])\n",
    "\n",
    "buckets=pd.Categorical(pd.cut(prec_index, [mymean - mysd* 10000, mymean - mysd * 2,  mymean - mysd, mymean - 0.5*mysd, mymean + 0.5*mysd, mymean + mysd, mymean + mysd *2, mymean + mysd* 10000])).rename_categories(['very very low','very low','low','average','high','very high','very very high'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(buckets)\n",
    "\n",
    "labelprec=le.transform(buckets)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "#dummy_y = np_utils.to_categorical(labelprec)\n",
    "nclasses=7\n",
    "dummy_y=to_categorical(labelprec,nclasses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3949404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 201, 721, 1440, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare Data for CNN\n",
    "\n",
    "# Split data into train and test\n",
    "cres_train, cres_test, crel_train, crel_test, netTOAcs_train, netTOAcs_test, y_train, y_test = train_test_split(cresIn, crelIn, netTOAcsIn, dummy_y,test_size=0.20, random_state=0)\n",
    "\n",
    "#Add extra dimension to data, required for algorithm\n",
    "crestrain=cres_train.values\n",
    "crestrain=crestrain[:,:,:,None]\n",
    "\n",
    "creltrain=crel_train.values\n",
    "creltrain=creltrain[:,:,:,None]\n",
    "\n",
    "netTOAcstrain=netTOAcs_train.values\n",
    "netTOAcstrain=netTOAcstrain[:,:,:,None]\n",
    "\n",
    "#---------------------------------------------------------\n",
    "crestest=cres_test.values\n",
    "crestest=crestest[:,:,:,None]\n",
    "\n",
    "creltest=crel_test.values\n",
    "creltest=creltest[:,:,:,None]\n",
    "\n",
    "netTOAcstest=netTOAcs_test.values\n",
    "netTOAcstest=netTOAcstest[:,:,:,None]\n",
    "\n",
    "X_test=np.array([crestest,creltest,netTOAcstest])\n",
    "X_train=np.array([crestrain,creltrain,netTOAcstrain])\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "X_train_reshape = np.einsum('lkija->klija',X_train)\n",
    "X_train_reshape.shape\n",
    "\n",
    "X_test_reshape = np.einsum('lkija->klija',X_test)\n",
    "X_test_reshape.shape\n",
    "\n",
    "### check for nan\n",
    "np.isnan(X_test_reshape).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c552a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 21:08:42.188259: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-07-13 21:08:42.188296: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-07-13 21:08:42.188317: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-16-155): /proc/driver/nvidia/version does not exist\n",
      "2022-07-13 21:08:42.189671: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/6 [=========>....................] - ETA: 5:08 - loss: 4.0664 - accuracy: 0.1719"
     ]
    }
   ],
   "source": [
    "# Fit model to training data\n",
    "# # define 10-fold cross validation test harness\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for train, test in kfold.split(X_train_reshape, y_train):\n",
    "    cnn3 = Sequential()\n",
    "    cnn3.add(Conv3D(8, kernel_size=5, activation='relu',padding='same',\n",
    "                    input_shape=(X_train_reshape[train].shape[1],\n",
    "                                 X_train_reshape[train].shape[2],X_train_reshape[train].shape[3],1)),)\n",
    "    cnn3.add(AveragePooling3D(pool_size=2,padding='same'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    \n",
    "    \n",
    "    cnn3.add(Flatten())\n",
    "    \n",
    "    \n",
    "    #Dense function adds a fully connected layer\n",
    "    #Hidden layer\n",
    "    cnn3.add(Dense(8, activation='relu'))\n",
    "    cnn3.add(Dropout(rate = 0.1))\n",
    "    #Output layer\n",
    "    cnn3.add(Dense(units= nclasses, activation = \"softmax\")) #units is always equal to number of classes\n",
    "    \n",
    "    \n",
    "    adam = keras.optimizers.Adam(lr=0.0001) # learning_rate\n",
    "    #Adam-A optimizer method for Stochastic Optimization\n",
    "    cnn3.compile(optimizer=adam, loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    epochs=10 # best average accuracy and lowest loss in validation data (cross-validation)\n",
    "    #hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, verbose=1, shuffle=True,\n",
    "                         #validation_data=(X_train_reshape[test], y_train[test]))\n",
    "        \n",
    "    hist = cnn3.fit(X_train_reshape[train], y_train[train],  epochs=epochs, verbose=1, shuffle=True,\n",
    "                         validation_data=(X_train_reshape[test], y_train[test]))\n",
    "    \n",
    "    # report performance\n",
    "    scores = cnn3.evaluate(X_train_reshape[test], y_train[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {cnn3.metrics_names[0]} of {scores[0]}; {cnn3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacd6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn3.predict(X_train_reshape)#, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea60798",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.argmax ( pred , axis=-1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb50da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted)\n",
    "y_true=np.argmax ( y_train , axis=-1 )\n",
    "print(y_true)\n",
    "\n",
    "cnt=0\n",
    "for i,p in enumerate(predicted):\n",
    "    if (p==y_true[i]):\n",
    "        cnt=cnt+1\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0d126",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = cnn3.predict(X_test_reshape)#, batch_size=batch_size)\n",
    "ytestPred=np.argmax ( pred_test , axis=-1 )\n",
    "ytruePred=np.argmax ( y_test , axis=-1 )\n",
    "print(ytestPred)\n",
    "print(ytruePred)\n",
    "\n",
    "cnt=0\n",
    "for i,p in enumerate(ytestPred):\n",
    "    if (p==ytruePred[i]):\n",
    "        cnt=cnt+1\n",
    "\n",
    "print(cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the confusion matrix\n",
    "#print(metrics.confusion_matrix(ytestPred,ytruePred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(ytestPred,ytruePred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c460d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10894e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b894b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages_environment",
   "language": "python",
   "name": "packages"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
